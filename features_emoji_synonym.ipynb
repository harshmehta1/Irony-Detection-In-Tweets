{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import wordnet \n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = \"SemEval2018-T3-train-taskA.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature to count number of emoticons in a tweet \n",
    "\n",
    "emoji = {\n",
    "    \":D\" : \"positive\", \":d\" : \"positive\", \":dd\" : \"positive\", \":P\" : \"positive\", \":-\" : \"negative\", \":\" : \"negative\",\n",
    "    \":p\" : \"positive\",\"8)\" : \"positive\", \"8-)\" : \"positive\",  \":-)\" : \"positive\", \":)\" : \"positive\", \";\" : \"negative\",\n",
    "    \";)\" : \"positive\",    \"(-:\" : \"positive\",    \"(:\" : \"positive\", \":')\" : \"positive\",    \"xD\" : \"positive\",    \n",
    "    \"XD\" : \"positive\",  \":/\" : \"negative\", \":-P\" : \"positive\", \":-p\" : \"positive\", \":O\" : \"negative\", \":v\" : \"positive\",\n",
    "    \":'(\" : \"negative\", \":-(\" : \"negative\", \":(\" : \"negative\", \":s\" : \"negative\",\":-s\" : \"negative\", \":]\" : \"positive\",\n",
    "    \"-_-\" : \"negative\", \"-.-\" : \"negative\", \":))\" : \"positive\", \":-)))\" : \"positive\", \":~)\" : \"positive\",\n",
    "    \";p\" : \"positive\", \";-)\" : \"positive\", \";**\" : \"positive\" }\n",
    "\n",
    "emoticon_count = defaultdict(lambda:0)\n",
    "f = open(file_path,encoding=\"utf8\")\n",
    "text = f.readlines()\n",
    "text = text[1:]\n",
    "for i in range(len(text)):\n",
    "    tweet = text[i]\n",
    "    for word in tweet.replace(\"|\", \" \").split():\n",
    "        if word.startswith(\":\") or word.startswith(\";\") or word.startswith(\"xD\"): \n",
    "            if word[1:].find(\":\") == -1:\n",
    "                if word in emoji:\n",
    "                    emoticon_count[i] +=1\n",
    "        else: \n",
    "            emoticon_count[i] += 0     \n",
    "\n",
    "emoji = set()\n",
    "replacements = [\"|\",\".\",\"#\",\"!\",\"@\",'\"',\",\"]\n",
    "for i in range(len(text)):\n",
    "    tweet = text[i]\n",
    "    for character in replacements:\n",
    "        tweet = tweet.replace(character, \" \")\n",
    "    tweet = tweet.replace(\"::\", \": :\")\n",
    "    tweet = tweet.replace(\":️\", \": \")\n",
    "    for word in tweet.split():\n",
    "        if word.startswith(\":\") and  word.endswith(\":\") and word != \":\":\n",
    "            emoticon_count[i] +=1\n",
    "            \n",
    "#emoticon_count \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature to count length of laughs in a tweet \n",
    "\n",
    "f = open(file_path,encoding=\"utf8\")\n",
    "text = f.readlines()\n",
    "text = text[1:]\n",
    "laugh_len = defaultdict(lambda:0) \n",
    "replacements = [\"|\",\":\",\".\",\"#\",\"!\",\"@\",'\"',\",\"]\n",
    "for i in range(len(text)):\n",
    "    tweet = text[i]\n",
    "    for character in replacements:\n",
    "        tweet = tweet.replace(character, \" \")\n",
    "    for word in tweet.split():\n",
    "        word = word.lower()\n",
    "        if \"lmao\" in word or \"rofl\" in word or \"laugh\" in word or word.startswith(\"lol\") or re.compile(r'(haha)').findall(word) or word == \"ha\" != [] :\n",
    "            laugh_len[i] += len(word)\n",
    "        else: \n",
    "            laugh_len[i]+=0\n",
    "\n",
    "#laugh_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emoticons_and_laughs = []\n",
    "for i in range(len(emoticon_count)):\n",
    "    emoticons_and_laughs.append(str(emoticon_count[i])+\"\\t\"+str(laugh_len[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_to_file(data, filename,column):\n",
    "    fo = open(filename+\".txt\",\"w+\")\n",
    "    \n",
    "    fo.write(column)\n",
    "    fo.write(\"\\n\")\n",
    "    for line in data:\n",
    "        fo.write(str(line))\n",
    "        fo.write(\"\\n\")\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_to_file(emoticons_and_laughs,\"emoticons_and_laughs\",\"emoticons\" + \"\\t\" + \"laugh_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature to count max, min and avg length of synonyms in a tweet\n",
    "synonyms_counts = []\n",
    "f = open(file_path,encoding=\"utf8\")\n",
    "max_synonyms = defaultdict(lambda:0) \n",
    "min_synonyms = defaultdict(lambda:0) \n",
    "avg_synonyms = defaultdict(lambda:0) \n",
    "text = f.readlines()[1:]\n",
    "replacements = [\"|\",\".\",\"#\",\"!\",\"@\",'\"',\",\",\"'\",\"/\"]\n",
    "for i in range(len(text)):\n",
    "    tweet = text[i]\n",
    "    synonyms = []\n",
    "    for character in replacements:\n",
    "        tweet = tweet.replace(character, \" \")\n",
    "    tweet = tweet.replace(\"::\", \": :\")\n",
    "    tweet = tweet.replace(\":️\", \": \")\n",
    "    for word in tweet.split()[2:]:\n",
    "        synonyms.append(len(wordnet.synsets(word)))\n",
    "    max_synonyms[i] = max(synonyms)\n",
    "    min_synonyms[i] = min(synonyms)\n",
    "    avg_synonyms[i] = np.mean(synonyms)\n",
    "    synonyms_counts.append(str(max(synonyms))+\"\\t\"+str(min(synonyms))+\"\\t\"+str(np.mean(synonyms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_to_file(synonyms_counts,\"synonyms\",\"max_syn_length\" + \"\\t\" + \"min_syn_length\"+ \"\\t\" + \"avg_syn_length\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
