{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "unigram_vector = np.load(\"unigram_vector.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open('text_stats.txt')\n",
    "text = fo.readlines()\n",
    "text = text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fo = open('text_stats.txt')\n",
    "text = fo.readlines()\n",
    "text = text[1:]\n",
    "char_count = []\n",
    "word_count =[]\n",
    "word_len_avg = []\n",
    "for row in text:\n",
    "    split = row.split('\\t')\n",
    "    punc.append(split[0])\n",
    "    ellipses.append(split[1])\n",
    "punc_count = np.array(punc)\n",
    "ellipses_count = np.array(ellipses)\n",
    "punctuations = np.column_stack((punc_count,ellipses_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fo = open('punctuation.txt')\n",
    "text = fo.readlines()\n",
    "text = text[1:]\n",
    "punc = []\n",
    "ellipses =[]\n",
    "for row in text:\n",
    "    split = row.split('\\t')\n",
    "    punc.append(split[0])\n",
    "    ellipses.append(split[1])\n",
    "punc_count = np.array(punc)\n",
    "ellipses_count = np.array(ellipses)\n",
    "punctuations = np.column_stack((punc_count,ellipses_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#char_count\tword_count\tcount_noun\tcount_verb\tcount_adverb\tcount_adjective\n",
    "char_count = []\n",
    "word_count = []\n",
    "count_noun = []\n",
    "count_verb = []\n",
    "count_adverb = []\n",
    "count_adjective = []\n",
    "\n",
    "fo = open('POS_tags.txt')\n",
    "text = fo.readlines()\n",
    "text=text[1:]\n",
    "for row in text:\n",
    "    split = row.split('\\t')\n",
    "    count_noun.append(split[0])\n",
    "    count_verb.append(split[1])\n",
    "    count_adverb.append(split[2])\n",
    "    count_adjective.append(split[3])\n",
    "\n",
    "array_noun=np.array(count_noun)\n",
    "array_verb=np.array(count_verb)\n",
    "array_adverb=np.array(count_adverb)\n",
    "array_adjective=np.array(count_adjective)\n",
    "pos_tags = np.column_stack((array_noun,array_verb,count_adverb,count_adjective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.column_stack((unigram_vector,punc_count,ellipses_count,pos_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Add text_statistics and bish ka features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
